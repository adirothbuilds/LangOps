#!/usr/bin/env python3
"""
Enhanced demo showing how to use JenkinsParser with JSON output for LLM analysis.
This extends the original analysis_jenkins_errors.py to include JSON-based prompts.

This script demonstrates:
1. Parsing Jenkins logs with structured data extraction.
2. Converting parsed data to JSON format.
3. Using JSON data in LLM prompts for better context and analysis.
4. Comparing traditional error parsing vs structured JenkinsParser approach.
5. Displaying results with colored terminal output for better readability.

This is a more advanced example that showcases the power of structured data
and how it can improve LLM interactions, especially for complex log analysis tasks.
This script requires the `langops` library and an OpenAI API key set in the environment.
Make sure to install the required dependencies and set up your environment before running this script.
"""

import os
from dotenv import load_dotenv
from colorama import Fore, Style, init
from langops import ParserRegistry, LLMRegistry

# Load environment variables from .env file
load_dotenv()

# Initialize colorama for colored terminal output
init(autoreset=True)

# Constants for demo
JENKINS_LOG_PATH = "demo/simulate_data/jenkins_logs.txt"
BUILD_ID = "12345"
TIMESTAMP = "2023-10-01T12:00:00Z"
CHARS_UNIT = " chars"


def analyze_jenkins_errors_with_json(log_path: str, build_id: str, timestamp: str):
    """
    Analyze Jenkins errors using both the traditional approach and JSON-based prompts.
    This function demonstrates how to parse Jenkins logs, extract structured data,
    and use it to query an LLM for insights.
    
    Args:
        log_path (str): Path to the Jenkins log file.
        build_id (str): Unique identifier for the build.
        timestamp (str): Timestamp of the build.
        
    Returns:
        None
    """
    print(Fore.BLUE + Style.BRIGHT + "üîç Parsing Jenkins log for errors using JenkinsParser..." + Style.RESET_ALL)
    
    # Use JenkinsParser instead of ErrorParser for more structured analysis
    jenkins_parser_cls = ParserRegistry.get_parser("JenkinsParser")
    jenkins_parser = jenkins_parser_cls()
    
    # Parse the log file and get structured data
    from langops.core.types import SeverityLevel
    log_content = jenkins_parser.handle_log_file(log_path)
    parsed_data = jenkins_parser.parse(log_content, min_severity=SeverityLevel.WARNING)
    
    print(Fore.GREEN + Style.BRIGHT + f"‚úÖ Found {len(parsed_data.stages)} stage(s) with issues." + Style.RESET_ALL)
    
    # Display summary
    summary = jenkins_parser.get_stages_summary(parsed_data)
    for stage_name, severity_counts in summary.items():
        total_issues = sum(severity_counts.values())
        print(Fore.CYAN + f"   üìã {stage_name}: " + Fore.YELLOW + f"{total_issues} issues " + Fore.WHITE + f"{severity_counts}" + Style.RESET_ALL)

    if not any(stage.logs for stage in parsed_data.stages):
        print(Fore.YELLOW + "‚ö†Ô∏è  No errors found." + Style.RESET_ALL)
        return

    print(Fore.MAGENTA + Style.BRIGHT + "\nüîÑ Converting to JSON format for LLM analysis..." + Style.RESET_ALL)
    
    # Method 1: Get clean JSON using Pydantic serialization
    json_data = parsed_data.model_dump_json(indent=2)
    print(Fore.CYAN + "üìÑ JSON structure preview:" + Style.RESET_ALL)
    print(Fore.WHITE + Style.DIM + (json_data[:300] + "..." if len(json_data) > 300 else json_data) + Style.RESET_ALL)

    print(Fore.BLUE + Style.BRIGHT + "\nü§ñ Querying LLM with structured JSON prompt..." + Style.RESET_ALL)
    
    # Create enhanced prompt with JSON data
    llm_prompt = f"""You are a Jenkins CI/CD expert. Analyze this build failure data and provide actionable insights.

**Build Information:**
- Build ID: {build_id}
- Timestamp: {timestamp}

**Structured Log Data:**
```json
{json_data}
```

**Analysis Requirements:**
1. **Root Cause Analysis**: Identify the primary failure reasons
2. **Stage-by-Stage Breakdown**: Analyze each failing stage  
3. **Fix Recommendations**: Provide specific, actionable solutions
4. **Prevention Strategy**: Suggest improvements to avoid future failures

**Response Format:**
Please structure your response with clear sections and prioritize critical issues first."""

    # Query LLM
    api_key = os.getenv("OPENAI_API_KEY")
    status_color = Fore.GREEN if api_key else Fore.RED
    status_text = "‚úÖ Found" if api_key else "‚ùå Not found"
    print(f"{status_color}üîë API Key status: {status_text}{Style.RESET_ALL}")
    
    if api_key:
        print(Fore.CYAN + "üîë OPENAI_API_KEY is set" + Style.RESET_ALL)
    
    if not api_key:
        print(Fore.YELLOW + "‚ö†Ô∏è  OPENAI_API_KEY not set. Skipping LLM analysis." + Style.RESET_ALL)
        print(Fore.CYAN + "üí° Here's the prompt that would be sent to the LLM:" + Style.RESET_ALL)
        print(Fore.YELLOW + "=" * 80 + Style.RESET_ALL)
        print(Fore.WHITE + llm_prompt + Style.RESET_ALL)
        print(Fore.YELLOW + "=" * 80 + Style.RESET_ALL)
        return

    try:
        llm_cls = LLMRegistry.get_llm("openai")
        llm = llm_cls(api_key=api_key)
        
        # Send structured prompt to LLM
        messages = [{"role": "user", "content": llm_prompt}]
        response = llm.complete(messages)

        print(Fore.GREEN + Style.BRIGHT + "\nüéØ LLM Analysis Results:" + Style.RESET_ALL)
        print(Fore.CYAN + "=" * 80 + Style.RESET_ALL)
        print(Fore.WHITE + response.text + Style.RESET_ALL)
        print(Fore.CYAN + "=" * 80 + Style.RESET_ALL)
        
        print(Fore.MAGENTA + Style.BRIGHT + "\nüìä Response Metadata:" + Style.RESET_ALL)
        for key, value in response.metadata.items():
            print(Fore.CYAN + f"   {key}: " + Fore.WHITE + f"{value}" + Style.RESET_ALL)
            
    except Exception as e:
        print(Fore.RED + f"‚ùå Error querying LLM: {e}" + Style.RESET_ALL)
        print(Fore.YELLOW + "üí° Prompt would have been:" + Style.RESET_ALL)
        print(Fore.WHITE + Style.DIM + llm_prompt[:500] + "..." + Style.RESET_ALL)


def compare_parsing_approaches(log_path: str):
    """
    Compare traditional ErrorParser vs new JenkinsParser approaches.
    This function demonstrates the differences in parsing Jenkins logs
    using both methods and highlights the benefits of structured data.
    
    Args:
        log_path (str): Path to the Jenkins log file.
        
    Returns:
        None
    """
    print(Fore.MAGENTA + Style.BRIGHT + "\nüî¨ Comparing Parsing Approaches:" + Style.RESET_ALL)
    print(Fore.CYAN + "=" * 50 + Style.RESET_ALL)
    
    # Traditional approach
    print(Fore.YELLOW + Style.BRIGHT + "1Ô∏è‚É£ Traditional ErrorParser:" + Style.RESET_ALL)
    error_parser = ParserRegistry.get_parser("ErrorParser")
    errors = error_parser.from_file(log_path)
    print(Fore.WHITE + "   Found " + Fore.CYAN + f"{len(errors)}" + Fore.WHITE + " raw error lines" + Style.RESET_ALL)
    if errors:
        print(Fore.WHITE + Style.DIM + f"   First error: {errors[0][:80]}..." + Style.RESET_ALL)
    
    # New structured approach  
    print(Fore.YELLOW + Style.BRIGHT + "\n2Ô∏è‚É£ New JenkinsParser (structured):" + Style.RESET_ALL)
    jenkins_parser_cls = ParserRegistry.get_parser("JenkinsParser")
    jenkins_parser = jenkins_parser_cls()
    from langops.core.types import SeverityLevel
    log_content = jenkins_parser.handle_log_file(log_path)
    parsed_data = jenkins_parser.parse(log_content, min_severity=SeverityLevel.WARNING)
    
    total_entries = sum(len(stage.logs) for stage in parsed_data.stages)
    print(Fore.WHITE + "   Found " + Fore.CYAN + f"{total_entries}" + Fore.WHITE + " structured log entries across " + Fore.CYAN + f"{len(parsed_data.stages)}" + Fore.WHITE + " stages" + Style.RESET_ALL)
    
    # Show JSON size comparison
    if errors:
        simple_json_size = len(str(errors))  # Rough estimate
        structured_json_size = len(parsed_data.model_dump_json())
        
        print(Fore.WHITE + "   Raw data size: " + Fore.YELLOW + f"~{simple_json_size}" + Fore.WHITE + CHARS_UNIT + Style.RESET_ALL)
        print(Fore.WHITE + "   Structured JSON size: " + Fore.GREEN + f"{structured_json_size}" + Fore.WHITE + CHARS_UNIT + Style.RESET_ALL)
        overhead_color = Fore.GREEN if structured_json_size - simple_json_size > 0 else Fore.RED
        print(Fore.WHITE + "   Structure overhead: " + overhead_color + f"+{structured_json_size - simple_json_size}" + Fore.WHITE + CHARS_UNIT + Style.RESET_ALL)
        
    print(Fore.GREEN + Style.BRIGHT + "\n‚úÖ Structured approach provides:" + Style.RESET_ALL)
    benefits = [
        "Stage-level organization",
        "Timestamp extraction",
        "Severity classification", 
        "Deduplication",
        "Better LLM context"
    ]
    for benefit in benefits:
        print(Fore.CYAN + "   ‚Ä¢ " + Fore.WHITE + benefit + Style.RESET_ALL)


if __name__ == "__main__":
    """
    Main entry point for the demo script.
    This function initializes the demo, checks for the log file,
    and runs the analysis and comparison functions.
    """
    print(Fore.CYAN + r"""
     _        _______  _        _______  _______  _______  _______ 
    ( \      (  ___  )( (    /|(  ____ \(  ___  )(  ____ )(  ____ \
    | (      | (   ) ||  \  ( || (    \/| (   ) || (    )|| (    \/
    | |      | (___) ||   \ | || |      | |   | || (____)|| (_____ 
    | |      |  ___  || (\ \) || | ____ | |   | ||  _____)(_____  )
    | |      | (   ) || | \   || | \_  )| |   | || (            ) |
    | (____/\| )   ( || )  \  || (___) || (___) || )      /\____) |
    (_______/|/     \||/    )_)(_______)(_______)|/       \_______)                                   
    """ + Fore.YELLOW + Style.BRIGHT + "                      L A N G O P S\n")

    print(Fore.RESET + Style.BRIGHT + "üöÄ Jenkins Parser with JSON LLM Integration Demo üöÄ\n")
    
    # Check if log file exists
    if not os.path.exists(JENKINS_LOG_PATH):
        print(Fore.RED + f"‚ùå Log file not found: {JENKINS_LOG_PATH}" + Style.RESET_ALL)
        print(Fore.YELLOW + "üí° Please ensure the demo data file exists." + Style.RESET_ALL)
        exit(1)
    
    # Run enhanced analysis
    analyze_jenkins_errors_with_json(JENKINS_LOG_PATH, BUILD_ID, TIMESTAMP)
    
    # Compare approaches
    compare_parsing_approaches(JENKINS_LOG_PATH)
    
    print(Fore.GREEN + Style.BRIGHT + "\nüéâ Demo completed!" + Style.RESET_ALL)
    print(Fore.CYAN + Style.BRIGHT + "\nüí° Key Benefits of JSON Approach:" + Style.RESET_ALL)
    
    benefits = [
        "Structured data for better LLM understanding",
        "Stage-aware analysis",
        "Consistent format across different log types",
        "Easy integration with other tools",
        "Preserves timestamp and severity information"
    ]
    
    for benefit in benefits:
        print(Fore.GREEN + "   ‚Ä¢ " + Fore.WHITE + benefit + Style.RESET_ALL)
